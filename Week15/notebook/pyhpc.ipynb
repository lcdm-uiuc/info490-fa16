{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<DIV ALIGN=CENTER>\n",
    "\n",
    "# Optimizing Python Performance\n",
    "## Professor Robert J. Brunner\n",
    "  \n",
    "</DIV>  \n",
    "-----\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "While writing (and maintaining) Python code is often much easier than\n",
    "writing similar code in more traditional high performance computing\n",
    "languages such as C, C++, or Fortran, Python is generally slower than\n",
    "similar programs written in higher performance languages. In those cases\n",
    "where end-to-end performance (i.e., concept to execution) is less\n",
    "important, perhaps because an application will be run many times, a\n",
    "programmer will need to consider new approaches to increase the\n",
    "performance of a Python program.\n",
    "\n",
    "Before proceeding further, however, some strong words of caution. Many\n",
    "programmers spend an inordinate amount of time on unneeded\n",
    "optimizations. To quote [Donald Knuth][dk] (1974 Turing Award Lecture):\n",
    "\n",
    "> Premature optimization is the root of all evil (or at least most of\n",
    "> it) in programming.\n",
    "\n",
    "Put simply, one should not worry about optimization until it has been\n",
    "shown to be necessary. And then one needs to very carefully decide what\n",
    "should can and should be optimized. This follows [Amdahl's law][al]\n",
    "which quantifies he maximum speed-up possible by improving the execution\n",
    "speed of only part of a program. For example, if only half of a program\n",
    "can be optimized, then the maximum possible speed-up is two times the\n",
    "original version. While modern multi- and many-core systems offer new\n",
    "performance benefits, they also come at an increased cost of code\n",
    "development, maintenance, and readability.\n",
    "\n",
    "Python, however, does provide both standard (i.e., included with the\n",
    "standard Python distribution) modules to leverage threading and\n",
    "multi-processing, as well as additional libraries and tools that can\n",
    "significantly improve the performance of specific types of applications.\n",
    "One major limitation that must be overcome when employing these\n",
    "techniques is the [_Global Interpreter Lock_][gil] or GIL. The GIL is\n",
    "used by the standard Python interpreter (known as CPython) to only allow\n",
    "one thread to execute Python code at one time. This is done to simplify\n",
    "the implementation of the Python object model and to safeguard against\n",
    "concurrent access. In other words, the entire Python interpreter is\n",
    "locked, and only one thread at a time is allowed access. \n",
    "\n",
    "While this simplifies the development of the Python interpreter, it\n",
    "diminishes the ability of Python programs to leverage the inherent\n",
    "parallelism that is available with multi-processor machines. Two caveats\n",
    "to the GIL are that the global lock is always released when doing IO\n",
    "operations (which might otherwise block or consume a lengthy period) and\n",
    "that either standard or third-party extension modules can explicitly\n",
    "release the global lock when doing computationally intensive tasks.\n",
    "\n",
    "In the rest of this Notebook, we will first explore standard Python\n",
    "modules for improving program performance. Next, we will explore the use\n",
    "of the IPython parallel programming capabilities. We will then discuss\n",
    "some non-standard extensions that can be used to improve application\n",
    "performance. We will finish with a quick introduction to several Python\n",
    "high performance \n",
    "\n",
    "-----\n",
    "\n",
    "[dk]: https://en.wikiquote.org/wiki/Donald_Knuth#Computer_Programming_as_an_Art_.281974.29\n",
    "[al]: https://en.wikipedia.org/wiki/Amdahl%27s_law\n",
    "[gil]: https://docs.python.org/3/glossary.html#term-global-interpreter-lock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Python Modules\n",
    "\n",
    "The Python interpreter comes with a number of standard modules that\n",
    "collectively form the [Python Standard Library][sl]. The Python3\n",
    "standard library contains a set of related modules for [concurrent\n",
    "execution][ce] that includes the `threading`, `multiprocessing`,\n",
    "`concurrent.futures`, `subprocess`, `sched`, and `queue` modules. In\n",
    "this section, we will quickly introduce the first two modules. Although\n",
    "the `concurrent` module looks promising as a way to employ either\n",
    "threads or processes in a similar manner.\n",
    "\n",
    "-----\n",
    "[pl]: https://docs.python.org/3.4/library/index.html\n",
    "[ce]: https://docs.python.org/3.4/library/concurrency.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Threads\n",
    "\n",
    "[Threads][t] are lightweight process element that can are often used to\n",
    "improve code performance by allowing multiple threads of program\n",
    "execution to occur within a single process. In Python, however, threads\n",
    "do not in general offer the same level of performance improvement seen\n",
    "in other languages since programming languages since Python employs the\n",
    "global interpreter lock. Yet the `threading` module still can offer some\n",
    "improvement to IO intensive applications and also can provide an easier\n",
    "path to learning how to effectively employ parallel programming (which\n",
    "will subsequently be useful when using other techniques such as the\n",
    "`multiprocessing` module or HPC constructs like _MPI_ or _OpenCL_.\n",
    "\n",
    "The `threading` module is built on the `Thread` object, which\n",
    "encapsulates the creation, interaction, and destruction of threads in a\n",
    "Python program. In this Notebook we will simply introduce the basic\n",
    "concepts; a number of [other resources][or] exist to provide additional\n",
    "details.\n",
    "\n",
    "TO use a thread in Python, we first mus create a `Thread` object, to\n",
    "which we can assign a name, a function to execute, and parameters that\n",
    "should be used within the threading function. For example, given a\n",
    "function `my_func` that takes a single integer value, we could create a\n",
    "new thread by executing the following Python statement:\n",
    "\n",
    "    t = threading.Thread(target=my_func, args=(10,))\n",
    "\n",
    "We build on this simple example in the following code cell to\n",
    "demonstrate how to create and use a worker thread.\n",
    "\n",
    "-----\n",
    "[t]: https://en.wikipedia.org/wiki/Thread_(computing)\n",
    "[or]: https://en.wikipedia.org/wiki/Thread_(computing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread #0 starting.\n",
      "\n",
      "Thread #1 starting.\n",
      "\n",
      "Thread #2 starting.\n",
      "\n",
      "Thread #3 starting.\n",
      "\n",
      "Thread #4 starting.\n",
      "\n",
      "Threads all created\n",
      "Computation = 1\n",
      "\n",
      "Thread #0 exiting.\n",
      "\n",
      "Computation = 10\n",
      "\n",
      "Thread #1 exiting.\n",
      "\n",
      "Computation = 100\n",
      "\n",
      "Thread #2 exiting.\n",
      "\n",
      "Computation = 1000\n",
      "\n",
      "Thread #3 exiting.\n",
      "\n",
      "Computation = 10000\n",
      "\n",
      "Thread #4 exiting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "# Generic worker thread\n",
    "def worker(num):\n",
    "        \n",
    "    # Get this Thread's name\n",
    "    name = threading.currentThread().getName()\n",
    "    \n",
    "    # Print Starting Message\n",
    "    print('{0:s} starting.\\n'.format(name), flush=True)\n",
    "    \n",
    "    # We sleep for two seconds\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Print computation\n",
    "    print('Computation = {0:d}\\n'.format(10**num), flush=True)\n",
    "    \n",
    "    # Print Exiting Message\n",
    "    print('{0:s} exiting.\\n'.format(name), flush=True)\n",
    "\n",
    "# We will spawn several threads.\n",
    "for i in range(5):\n",
    "    t = threading.Thread(name='Thread #{0:d}'.format(i), target=worker, args=(i,))\n",
    "    t.start()\n",
    "    \n",
    "print(\"Threads all created\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing\n",
    "\n",
    "One way to circumvent the GIL is to use multiple Python interpreters that each run in their own process. This can be accomplished by using the `multiprocessing` module. In this module, processes essentially take the place of threads, but since each process will read the same Python code file, we need to ensure that only one process (the main process) creates the other processes, or else we can create an infinite loop that quickly consumes all hardware resources. This is done by using the following statement prior to the main program body:\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "\n",
    "Inside the main program code, we can create Processes and start them in a similar manner as we did with threads earlier.\n",
    "\n",
    "-----\n",
    "[mp]: http://pymotw.com/2/multiprocessing/index.html#module-multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process #1 starting.\n",
      "Process #0 starting.\n",
      "Process #2 starting.\n",
      "\n",
      "\n",
      "\n",
      "Computation = 1\n",
      "Computation = 0\n",
      "Computation = 1024\n",
      "\n",
      "\n",
      "\n",
      "Process #1 exiting.\n",
      "Process #0 exiting.\n",
      "Process #2 exiting.\n",
      "\n",
      "\n",
      "\n",
      "Processing complete\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing \n",
    "import time\n",
    "\n",
    "# Generic worker process\n",
    "def worker(num):\n",
    "        \n",
    "    # Get this Process' name\n",
    "    name = multiprocessing.current_process().name\n",
    "    \n",
    "    # Print Starting Message\n",
    "    print('{0:s} starting.\\n'.format(name))\n",
    "    \n",
    "    # We sleep for two seconds\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Print computation\n",
    "    print('Computation = {0:d}\\n'.format(num**10))\n",
    "    \n",
    "    # Print Exiting Message\n",
    "    print('{0:s} exiting.\\n'.format(name))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # We will spawn several processes.\n",
    "    for i in range(3):\n",
    "        p = multiprocessing.Process(name='Process #{0:d}'.format(i), target=worker, args=(i,))\n",
    "        p.start()\n",
    "        \n",
    "    print(\"Processing complete\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPython Cluster\n",
    "\n",
    "The [Ipython Server][ipy] has built-in support for parallel processing.\n",
    "This can be initialized in an automated manner by using the `ipcluster`\n",
    "command, or in a manual approach by using the `ipcontroller` and\n",
    "`ipengine` commands. The first approach simply automated the process of\n",
    "using the controller and engines, and requires the creation of a IPYthon\n",
    "profile, which is done by using the `ipython profile create` command.\n",
    "`ipcluster` works with both MPI and batch processing clusters (ew.g.,\n",
    "via PBS), and can be made to work with other schedulers such as condor.\n",
    "\n",
    "If necessary, you can also manually control the process by directly\n",
    "instantiating the IPython controller and engines. The controller must be\n",
    "started first, after which you can create as many engines as necessary,\n",
    "given your hardware constraints. IPython clustering works best on\n",
    "multi-processing machines or compute clusters.\n",
    "\n",
    "-----\n",
    "\n",
    "[ipy]: http://ipython.org/ipython-doc/dev/parallel/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third-Party Python Tools\n",
    "\n",
    "There are a number of third-party Python modules or packages that can be\n",
    "used to improve the performance of a Python application.\n",
    "\n",
    "1. [Numba][nj] is a just in time compiler from Continuum Analytics that\n",
    "can increase the performance of certain  functions (e.g., numerical\n",
    "work).\n",
    "\n",
    "2. [PYPY][py] is an alternative implementation of the Python language\n",
    "that includes a just in time compiler that speeds up many Python\n",
    "programs.\n",
    "\n",
    "3. [Cython][cy] is a static optimizing compiler for Python and also\n",
    "provides a method for easily including C or C++ code in a Python program.\n",
    "\n",
    "-----\n",
    "\n",
    "[nj]: http://numba.pydata.org\n",
    "[py]: http://pypy.org\n",
    "[cy]: http://cython.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python and HPC\n",
    "\n",
    "While Python programs can be easily used for embarrassingly parallel\n",
    "programming on high performance compute systems and Python is also used\n",
    "to glue advanced computation programs together for batch processing\n",
    "there are also projects underway that enable Python code to directly\n",
    "leverage high performance programming paradigms:\n",
    "\n",
    "- [MPI][m] is message passing interface and is a protocol used to\n",
    "communicate messages (or data) between compute nodes in a large,\n",
    "distributed compute cluster. [mpi4py][m2] is a Python module that\n",
    "brings a significant part of the MPI specification to Python programs.\n",
    "\n",
    "- [OpenCL][o] is a framework that enables programs to run on heterogeneous\n",
    "platforms including CPUs, GPUs, DSP, and FPGAs. The [Python OpenCL][po]\n",
    "package enables Python programs to use OpenCL to write code that runs on\n",
    "these different processor types efficiently and effectively.\n",
    "\n",
    "-----\n",
    "[m]: https://en.wikipedia.org/wiki/Message_Passing_Interface\n",
    "[m2]: https://bitbucket.org/mpi4py/mpi4py/overview\n",
    "[o]: https://en.wikipedia.org/wiki/OpenCL\n",
    "[po]: http://mathema.tician.de/software/pyopencl/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
